---
title: "Homework 2 for P8131"
author: "Roxy Zhang"
date: "2/18/2022"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

# Question 1

## Format data

```{r}
dose = c(0:4)
death = c(2, 8, 15, 23, 27)
survival = rep(30, 5) - death

df1 = data.frame(dose, death, survival)
y1 = as.matrix(df1[ , -1])
```

## Logit link

```{r}
# fit a glm model
logit_fit <- glm(
  y1 ~ dose, 
  data = df1,
  family = binomial(link = 'logit'))

summary(logit_fit)

# extract estimated beta
logit_fit$coefficients
round(logit_fit$coefficients[2], 3)

# calculate CI (asymptotic)
round(confint.default(logit_fit),3)

# extract deviance
round(logit_fit$deviance, 3)
# calculate deviance "by hand"
round(sum(residuals(logit_fit, type = 'deviance' ) ^ 2), 3)

# make prediction
round(predict.glm(logit_fit, newdata = data.frame(dose = 0.01), type = 'response'), 4) # type = "response" gives the predicted probabilities
```


## Probit link

```{r}
# fit a glm model
probit_fit <- glm(
  y1 ~ dose, 
  data = df1,
  family = binomial(link = 'probit'))

summary(probit_fit)

# extract estimated beta
probit_fit$coefficients
round(probit_fit$coefficients[2], 3)

# calculate CI
round(confint.default(probit_fit),3)

# extract deviance
round(probit_fit$deviance, 3)

# calculate deviance "by hand"
round(sum(residuals(probit_fit, type = 'deviance' ) ^ 2), 3)

# make prediction
round(predict.glm(probit_fit, newdata = data.frame(dose = 0.01),type = 'response'), 4)
```


## Log-log link

```{r}
# fit a glm model
ll_fit <- glm(
  y1 ~ dose, 
  data = df1,
  family = binomial(link = 'cloglog'))

summary(ll_fit)

# extract estimated beta
ll_fit$coefficients
round(ll_fit$coefficients[2], 3)

# calculate CI
round(confint.default(ll_fit),3)

# extract deviance
round(ll_fit$deviance, 3)

# calculate deviance "by hand"
round(sum(residuals(ll_fit, type = 'deviance' ) ^ 2), 3)

# make prediction
round(predict.glm(ll_fit, newdata = data.frame(dose = 0.01),type = 'response'), 4)
```


## Estimate LD50 with 90% CI

```{r}
# logit

beta0_logit = logit_fit$coefficients[1]
beta1_logit = logit_fit$coefficients[2]

# inverse fisher information
beta_cov_logit = vcov(logit_fit)

xhat_logit = - beta0_logit/ beta1_logit

# point estimate of x0
round(exp(xhat_logit),3)

var_xhat_logit = beta_cov_logit[1,1]/(beta1_logit^2) + beta_cov_logit[2,2]*(beta0_logit^2)/(beta1_logit^4)
 - 2*beta_cov_logit[1,2]*beta0_logit/(beta1_logit^3)

xhat_logit + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_logit)

logit_row = round(exp(xhat_logit + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_logit)), 3)
```

```{r}
# probit
beta0_probit = probit_fit$coefficients[1]
beta1_probit = probit_fit$coefficients[2]

beta_cov_probit = vcov(probit_fit)

xhat_probit = - beta0_probit/ beta1_probit

var_xhat_probit = beta_cov_probit[1,1]/(beta1_probit^2) + beta_cov_probit[2,2]*(beta0_probit^2)/(beta1_probit^4)
 - 2*beta_cov_probit[1,2]*beta0_probit/(beta1_probit^3)

xhat_probit + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_probit)

probit_row = round(exp(xhat_probit + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_probit)), 3)
```

```{r}
# log-log
c = log(-log(0.5))

beta0_ll = ll_fit$coefficients[1]
beta1_ll = ll_fit$coefficients[2]

beta_cov_ll = vcov(ll_fit)

xhat_ll = (c - beta0_ll)/ beta1_ll

var_xhat_ll = beta_cov_ll[1,1]/(beta1_ll^2) + beta_cov_ll[2,2]*(c - beta0_ll^2)/(beta1_ll^4) - 2*beta_cov_ll[1,2]*(c - beta0_ll)/(beta1_ll^3)

xhat_ll + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_ll)

ll_row = round(exp(xhat_ll + c(0, qnorm(0.05), - qnorm(0.05)) * sqrt(var_xhat_ll)), 3)
```

```{r}
ci_df = data.frame(rbind(logit_row, probit_row, ll_row)) %>% 
  rename(
    "Estimate LD50" = X1,
    "90% CI Lower" = X2,
    "90% CI Upper" = X3
  )

row.names(ci_df) = c("logit", "probit", "log-log")

ci_df %>% 
  knitr::kable()
```




# Question 2

```{r}
# input data
amount = seq(10, 90, 5)
offers = c(4, 6, 10, 12, 39, 36, 22, 14, 10, 12, 8, 9, 3, 1, 5, 2, 1)
enrolls = c(0, 2, 4, 2, 12, 14, 10, 7, 5, 5, 3, 5, 2, 0, 4, 2, 1)

df2 = data.frame(amount, offers, enrolls)
```

```{r}
# fit a logistic regression model
offer_fit <- glm(
  cbind(enrolls, offers - enrolls) ~ amount, 
  data = df2,
  family = binomial(link = 'logit'))

# conduct Hosmer-Lemeshow test for sparse data
library(ResourceSelection)
hoslem.test(offer_fit$y, fitted(offer_fit), g=10)
```

```{r}
# model interpretation
summary(offer_fit)

# standard error
sqrt(vcov(offer_fit)[2,2])

# CI for odds ratio
exp(confint.default(offer_fit))
```

```{r}
# scholarship of 40% enrollment rate
x0fit = (log(2/3) + 1.648) / 0.031

# 95% CI
beta0_offer = offer_fit$coefficients[1]
beta1_offer = offer_fit$coefficients[2]
betacov = vcov(offer_fit)

varx0 = betacov[1,1]/(beta1_offer^2)+betacov[2,2]*((c-beta0_offer)^2)/(beta1_offer^4)
+2*betacov[1,2]*(c-beta0_offer)/(beta1_offer^3)

round((x0fit+c(qnorm(0.025),0,-qnorm(0.025))*sqrt(varx0)),3)
```

